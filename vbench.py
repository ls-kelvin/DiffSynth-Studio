import os

os.environ["MLLM_NO_CFG"] = "1"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

import json
import argparse
import re
from pathlib import Path
import torch
from accelerate import Accelerator
from diffsynth.utils.data import save_video
from diffsynth.pipelines.wan_video_autoregressive import WanVideoAutoregressivePipeline, ModelConfig
from diffsynth.core.data.unified_dataset import UnifiedDataset


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--jsonl_path", type=str, default="/root/workspace/zzt/data/UltraVideo/vbench_expand.jsonl",
                        help="Path to JSONL file with fields: {'prompt': str, 'video_file': str}")
    parser.add_argument("--prompt_type", type=str, default="extended_prompt")
    parser.add_argument("--lora_step", type=int, default=48800)
    parser.add_argument("--run_cate", type=str, default="local_vae")
    parser.add_argument("--output_dir", type=str, default=None)
    parser.add_argument("--seed", type=int, default=1)
    parser.add_argument("--fps", type=int, default=15)
    parser.add_argument("--quality", type=int, default=5)
    parser.add_argument("--disable_mllm", action="store_false", help="Enable MLLM condition (default: True)")
    parser.add_argument("--tiled", action="store_true")
    return parser.parse_args()


def sanitize_filename(s, max_len=40):
    # ç§»é™¤/æ›¿æ¢éæ³•å­—ç¬¦ï¼Œä¿ç•™ä¸­è‹±æ–‡ã€æ•°å­—ã€ç©ºæ ¼ã€å¸¸è§æ ‡ç‚¹
    s = re.sub(r'[<>:"/\\|?*\x00-\x1f]', '_', s)
    s = s.strip().replace(' ', '_')
    return s[:max_len]


def load_jsonl(path):
    data = []
    with open(path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            try:
                item = json.loads(line.strip())
                data.append(item)
            except json.JSONDecodeError as e:
                print(f"âš ï¸ Line {line_num} JSON error: {e}")
    return data


def main():
    args = parse_args()
    accelerator = Accelerator()
    rank = accelerator.process_index
    world_size = accelerator.num_processes

    # Fixed negative prompt
    NEG_PROMPT = "è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°"

    # Load data
    all_items = load_jsonl(args.jsonl_path)
    local_items = all_items[rank::world_size]  # Shard by rank

    accelerator.print(f"[Rank {rank}] Assigned {len(local_items)} / {len(all_items)} items.")

    pipe = WanVideoAutoregressivePipeline.from_pretrained(
        torch_dtype=torch.bfloat16,
        device=accelerator.device,
        model_configs=[
            ModelConfig(path="/root/workspace/zzt/models/Wan-AI/Wan2.1-T2V-1.3B/diffusion_pytorch_model.safetensors"),
            ModelConfig(path="/root/workspace/zzt/models/Wan-AI/Wan2.1-T2V-1.3B/models_t5_umt5-xxl-enc-bf16.pth"),
            ModelConfig(path="/root/workspace/zzt/models/Wan-AI/Wan2.1-T2V-1.3B/Wan2.1_VAE.pth"),
            ModelConfig(path=[
                "/root/workspace/zzt/models/Qwen/Qwen3-VL-4B-Instruct/model-00001-of-00002.safetensors",
                "/root/workspace/zzt/models/Qwen/Qwen3-VL-4B-Instruct/model-00002-of-00002.safetensors"
            ])
        ],
        tokenizer_config=ModelConfig(path="/root/workspace/zzt/models/Wan-AI/Wan2.1-T2V-1.3B/google/umt5-xxl"),
        mllm_processor_config=ModelConfig(path="/root/workspace/zzt/models/Qwen/Qwen3-VL-4B-Instruct")
    )

    # Load LoRA
    lora_path = f"./models/train/Wan2.1-T2V-1.3B_lora_ultravideo_{args.run_cate}/step-{args.lora_step}.safetensors"
    if args.lora_step != 0:
        pipe.load_lora(pipe.dit, lora_path, alpha=1.0)
        if rank == 0:
            print(f"âœ… LoRA loaded: {lora_path}")

    # Output dir
    output_dir = args.output_dir or f"output_videos/{args.lora_step}/{args.run_cate}/vbench_expand"
    os.makedirs(output_dir, exist_ok=True)

    # Process one-by-one
    for i, item in enumerate(local_items):
        prompt = item[args.prompt_type]
        
        filename = f"{item['prompt']}.mp4"
        save_path = os.path.join(output_dir, f"{item['prompt']}-0.mp4")
        
        if os.path.exists(save_path):
            continue

        try:
            # Generate single video
            output_video = pipe(
                prompt=prompt,
                negative_prompt=NEG_PROMPT,
                # input_video=input_video,
                seed=args.seed,
                tiled=args.tiled,
                # use_mllm_condition=args.use_mllm,
                # mllm_neg_mode="full",
                num_frames=93
            )

            # Safe filename: {video_stem}_{sanitized_prompt_head}_ori.mp4


            # Avoid overwrite: add _1, _2, ... if exists
            counter = 1
            while os.path.exists(save_path):
                name, ext = os.path.splitext(filename)
                save_path = f"{output_dir}/{name}-{counter}{ext}"
                counter += 1

            save_video(output_video, save_path, fps=args.fps, quality=args.quality)
            accelerator.print(f"âœ… [Rank {rank}] Saved: {save_path}")

        except Exception as e:
            accelerator.print(f"âŒ [Rank {rank}] Error on item {i} (video: {item['prompt']}): {e}")
            continue

    accelerator.wait_for_everyone()
    if rank == 0:
        print("ğŸ‰ All done!")


if __name__ == "__main__":
    main()